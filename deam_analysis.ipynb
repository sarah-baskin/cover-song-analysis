{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60eee99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOMORROW\n",
    "#TODO: go over code, clean it up and make it look presentable \n",
    "# -- make sure that the loops are all accurate and everything's working in the way it should\n",
    "# -- figure out why smoothing isn't making things better???\n",
    "#TODO: Rerun training (2 hours) and covers1000 (30 mins) evaluation\n",
    "#TODO: analysis of given labels for song-level valence and arousal for DEAM compared to my results\n",
    "#TODO: Formal analysis of covers1000 including comparison of covers v + a to original\n",
    "#TODO: Start writing paper (goal: abstract, introduction, literature review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30948065",
   "metadata": {},
   "source": [
    "# DEAM Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6bccfc",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00265c9d",
   "metadata": {
    "id": "00265c9d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2255be9",
   "metadata": {
    "id": "b2255be9"
   },
   "outputs": [],
   "source": [
    "def compute_beats(y, sr, hop_length):\n",
    "\n",
    "    tempo, beat_frames = librosa.beat.beat_track(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        hop_length=hop_length,\n",
    "        units=\"frames\"\n",
    "    )\n",
    "\n",
    "    beat_times_sec = librosa.frames_to_time(\n",
    "        beat_frames,\n",
    "        sr=sr,\n",
    "        hop_length=hop_length\n",
    "    )\n",
    "\n",
    "    return beat_times_sec, beat_frames, tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24eaaaa",
   "metadata": {
    "id": "b24eaaaa"
   },
   "outputs": [],
   "source": [
    "def aggregate_feature(mfcc, cens, beat_frames, beat_times):\n",
    "\n",
    "    X = []\n",
    "    durations = []\n",
    "\n",
    "    for t in range(len(beat_frames) - 1):\n",
    "        start = beat_frames[t]\n",
    "        end   = beat_frames[t + 1]\n",
    "\n",
    "        if end > start:\n",
    "            mfcc_t = mfcc[start:end].mean(axis=0)\n",
    "            cens_t = cens[start:end].mean(axis=0)\n",
    "        else:\n",
    "            mfcc_t = mfcc[start]\n",
    "            cens_t = cens[start:end]\n",
    "\n",
    "        X.append(np.concatenate([mfcc_t, cens_t]))\n",
    "        durations.append(beat_times[t + 1] - beat_times[t])\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    return X, np.array(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8406bd5f",
   "metadata": {
    "id": "8406bd5f"
   },
   "outputs": [],
   "source": [
    "def parse_annotation_times(df):\n",
    "\n",
    "    time_cols = [c for c in df.columns if c.startswith(\"sample_\")]\n",
    "\n",
    "    times_sec = np.array([int(c.replace(\"sample_\", \"\").replace(\"ms\", \"\")) / 1000.0\n",
    "                          for c in time_cols])\n",
    "\n",
    "    return time_cols, times_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e07b74",
   "metadata": {
    "id": "c5e07b74"
   },
   "outputs": [],
   "source": [
    "def aggregate_annotations_to_beats(\n",
    "        times_sec,\n",
    "        values,\n",
    "        beat_times_sec\n",
    "):\n",
    "\n",
    "    y_beats = []\n",
    "\n",
    "    for t in range(len(beat_times_sec) - 1):\n",
    "        start = beat_times_sec[t]\n",
    "        end   = beat_times_sec[t + 1]\n",
    "\n",
    "        mask = (times_sec >= start) & (times_sec < end)\n",
    "\n",
    "        if np.any(mask):\n",
    "            y_beats.append(values[mask].mean())\n",
    "        else:\n",
    "            idx = np.argmin(np.abs(times_sec - start))\n",
    "            y_beats.append(values[idx])\n",
    "    return np.array(y_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d3ed5d",
   "metadata": {
    "id": "b9d3ed5d"
   },
   "outputs": [],
   "source": [
    "def get_song_ids(filepath):\n",
    "\n",
    "    ids = []\n",
    "    for _, _, files in os.walk(filepath):\n",
    "        for file in files:\n",
    "            if \".mp3\" in file:\n",
    "                ids.append(file[:file.index(\".\")])\n",
    "\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d42175ed",
   "metadata": {
    "id": "d42175ed"
   },
   "outputs": [],
   "source": [
    "def compute_normalization(loader):\n",
    "    X_all = []\n",
    "\n",
    "    for X, _, _, _ in loader:\n",
    "        if X is None:\n",
    "            continue\n",
    "        X_all.append(X)\n",
    "\n",
    "    if len(X_all) == 0:\n",
    "        raise RuntimeError(\"No valid samples found\")\n",
    "\n",
    "    X_all = torch.cat(X_all, dim=0)\n",
    "    mean = X_all.mean(dim=0)\n",
    "    std = X_all.std(dim=0) + 1e-6\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776a71ab",
   "metadata": {
    "id": "776a71ab"
   },
   "outputs": [],
   "source": [
    "def flatten_collate(batch):\n",
    "\n",
    "    batch = [b for b in batch if b is not None]\n",
    "\n",
    "    if len(batch) == 0:\n",
    "        return None, None\n",
    "\n",
    "    X_list = [b[\"X\"] for b in batch]\n",
    "    y_list = [b[\"y\"] for b in batch]\n",
    "\n",
    "    X = torch.cat(X_list, dim=0)\n",
    "    y = torch.cat(y_list, dim=0)\n",
    "\n",
    "    durations = torch.cat([b[\"durations\"] for b in batch], dim=0)\n",
    "\n",
    "    song_ids = []\n",
    "    for b in batch:\n",
    "        song_ids.extend([b[\"song_id\"]] * len(b[\"X\"]))\n",
    "\n",
    "    return X, y, durations, song_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "136a8a7b",
   "metadata": {
    "id": "136a8a7b"
   },
   "outputs": [],
   "source": [
    "class BeatRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "\n",
    "        super().__init__()\n",
    "        self.next = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e06a37c5",
   "metadata": {
    "id": "e06a37c5"
   },
   "outputs": [],
   "source": [
    "class DEAMDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            audio_dir,\n",
    "            arousal_labels,\n",
    "            valence_labels,\n",
    "            song_ids,\n",
    "            hop_length=512,\n",
    "            n_mfcc=20\n",
    "    ):\n",
    "\n",
    "        self.audio_dir = audio_dir\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.song_ids = song_ids\n",
    "        self.cache = {}\n",
    "        \n",
    "        self.arousal_labels = pd.read_csv(arousal_labels)\n",
    "        self.valence_labels = pd.read_csv(valence_labels)\n",
    "        self.time_cols, self.time_sec = parse_annotation_times(self.valence_labels)\n",
    "        self.valence_labels[\"song_id\"] = self.valence_labels[\"song_id\"].astype(str).str.strip()\n",
    "        self.arousal_labels[\"song_id\"] = self.arousal_labels[\"song_id\"].astype(str).str.strip()\n",
    "        self.valence_dict = self.valence_labels.set_index(\"song_id\")\n",
    "        self.arousal_dict = self.arousal_labels.set_index(\"song_id\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.song_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        song_id = self.song_ids[idx]\n",
    "\n",
    "        if song_id in self.cache:\n",
    "          return self.cache[song_id]\n",
    "\n",
    "        path = os.path.join(self.audio_dir, f\"{song_id}.mp3\")\n",
    "\n",
    "        y, sr = librosa.load(path, sr=22050, mono=True)\n",
    "\n",
    "        _, beat_frames = librosa.beat.beat_track(\n",
    "          y=y, sr=sr, hop_length=self.hop_length, units=\"frames\"\n",
    "        )\n",
    "\n",
    "        beat_times_sec = librosa.frames_to_time(beat_frames, sr=sr, hop_length=self.hop_length)\n",
    "\n",
    "        if beat_times_sec is None or len(beat_times_sec) < 2:\n",
    "          return None\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            n_mfcc=self.n_mfcc,\n",
    "            hop_length=self.hop_length\n",
    "        ).T\n",
    "\n",
    "        cens = librosa.feature.chroma_cens(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            hop_length=self.hop_length\n",
    "        ).T\n",
    "\n",
    "        X, durations = aggregate_feature(mfcc, cens, beat_frames, beat_times_sec)\n",
    "\n",
    "        valence = self.valence_dict.loc[str(song_id), self.time_cols].values\n",
    "        arousal = self.arousal_dict.loc[str(song_id), self.time_cols].values\n",
    "\n",
    "        val_beats = aggregate_annotations_to_beats(self.time_sec, valence, beat_times_sec)\n",
    "        aro_beats = aggregate_annotations_to_beats(self.time_sec, arousal, beat_times_sec)\n",
    "\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "        y = np.column_stack([val_beats, aro_beats])\n",
    "\n",
    "        valid = ~np.isnan(y).any(axis=1)\n",
    "\n",
    "        X = X[valid]\n",
    "        y = y[valid]\n",
    "        durations = durations[valid]\n",
    "\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        durations = torch.tensor(durations, dtype=torch.float32)\n",
    "\n",
    "        if X.shape[0] == 0 or y.shape[0] == 0:\n",
    "          return None\n",
    "\n",
    "        if not torch.isfinite(X).all():\n",
    "          return None\n",
    "        if not torch.isfinite(y).all():\n",
    "          return None\n",
    "\n",
    "        sample = {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"durations\": durations,\n",
    "            \"song_id\": song_id\n",
    "        }\n",
    "\n",
    "        self.cache[song_id] = sample\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b119080",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b119080",
    "outputId": "30bcb7bf-4755-452b-8e12-e3f23d33de9d"
   },
   "outputs": [],
   "source": [
    "ids = get_song_ids(\"DEAM_Dataset/DEAM_audio/MEMD_audio\")\n",
    "\n",
    "dataset = DEAMDataset(\"DEAM_Dataset/DEAM_audio/MEMD_audio\",\n",
    "                           \"DEAM_Dataset/DEAM_Annotations/annotations/annotations averaged per song/dynamic (per second annotations)/arousal.csv\",\n",
    "                           \"DEAM_Dataset/DEAM_Annotations/annotations/annotations averaged per song/dynamic (per second annotations)/valence.csv\",\n",
    "                           ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68f15e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [14:29<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Precomputing features...\")\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    _ = dataset[i]\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e179c61f",
   "metadata": {
    "id": "e179c61f"
   },
   "outputs": [],
   "source": [
    "num_songs = len(dataset)\n",
    "indices = np.arange(num_songs)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a4d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beat_level(song_id, preds, smoothed, covs):\n",
    "    t = np.arange(len(preds))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "    labels = [\"Valence\", \"Arousal\"]\n",
    "    for d in range(2):\n",
    "        std = np.sqrt(covs[:, d, d])\n",
    "        ci = 1.96 * std\n",
    "\n",
    "        axes[d].plot(t, preds[:, d], alpha=0.4, label=\"Raw\")\n",
    "        axes[d].plot(t, smoothed[:, d], label=\"Smoothed\", linewidth=2)\n",
    "        axes[d].fill_between(\n",
    "            t,\n",
    "            smoothed[:, d] - ci,\n",
    "            smoothed[:, d] + ci,\n",
    "            alpha=0.2,\n",
    "            label=\"95% CI\"\n",
    "        )\n",
    "        axes[d].set_ylabel(labels[d])\n",
    "        axes[d].legend()\n",
    "\n",
    "    axes[-1].set_xlabel(\"Beat index\")\n",
    "    fig.suptitle(f\"Beat-level emotion trajectory: {song_id}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8dc4911",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8dc4911",
    "outputId": "3defa827-3682-4777-84bd-43b88899f868"
   },
   "outputs": [],
   "source": [
    "def full_monty(device):\n",
    "\n",
    "    fold_results = []\n",
    "    all_songs_val_and_aro = []\n",
    "    per_fold_beat_uncertainty = {}\n",
    "\n",
    "    unsm_val_r = []\n",
    "    sm_val_r = []\n",
    "    unsm_aro_r = []\n",
    "    sm_aro_r = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "        print(f\"===== Fold {fold + 1} of 10 =====\")\n",
    "\n",
    "        train_set = Subset(dataset, train_idx)\n",
    "        val_set = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_set,\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            collate_fn=flatten_collate\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            dataset=val_set,\n",
    "            batch_size=8,\n",
    "            shuffle=False,\n",
    "            collate_fn=flatten_collate\n",
    "        )\n",
    "\n",
    "        mean, std = compute_normalization(train_loader)\n",
    "\n",
    "        input_dim = train_set[0][\"X\"].shape[1]\n",
    "        model = BeatRegressor(input_dim).to(device)\n",
    "        optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "\n",
    "        for epoch in range(30):\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0.0\n",
    "            n_batches = 0\n",
    "\n",
    "            for X, y, _, _ in train_loader:\n",
    "                X = ((X - mean) / std).to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "            train_loss /= n_batches\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            n_batches = 0\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for X, y, _, _ in val_loader:\n",
    "                    X = ((X - mean) / std).to(device)\n",
    "                    y = y.to(device)\n",
    "\n",
    "                    y_hat = model(X)\n",
    "                    val_loss += criterion(y_hat, y).item()\n",
    "                    n_batches += 1\n",
    "\n",
    "            val_loss /= n_batches\n",
    "            best_val_loss = min(best_val_loss, val_loss)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1:02d} | \"\n",
    "                f\"Train MSE: {train_loss:.4f} | \"\n",
    "                f\"Val MSE: {val_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "        fold_results.append(best_val_loss)\n",
    "\n",
    "        model.eval()\n",
    "        train_song_preds = defaultdict(list)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, _, _, song_ids in train_loader:\n",
    "                X = ((X - mean) / std).to(device)\n",
    "                y_hat = model(X).cpu().numpy()\n",
    "\n",
    "                for i, song_id in enumerate(song_ids):\n",
    "                    train_song_preds[song_id].append(y_hat[i])\n",
    "\n",
    "        pred_sequences = []\n",
    "        for preds in train_song_preds.values():\n",
    "            preds = np.asarray(preds, dtype=np.float64)\n",
    "            if preds.ndim != 2:\n",
    "                continue\n",
    "            if preds.shape[0] < 5:\n",
    "                continue\n",
    "            if not np.isfinite(preds).all():\n",
    "                continue\n",
    "            pred_sequences.append(preds)\n",
    "\n",
    "        kalman = KalmanFilter(\n",
    "            n_dim_state=2,\n",
    "            n_dim_obs=2,\n",
    "            transition_matrices=np.eye(2),\n",
    "            observation_matrices=np.eye(2),\n",
    "            transition_covariance=0.01 * np.eye(2),\n",
    "            observation_covariance=0.1 * np.eye(2),\n",
    "            initial_state_mean=np.zeros(2),\n",
    "            initial_state_covariance=np.eye(2)\n",
    "        )\n",
    "\n",
    "        X_concat = np.vstack(pred_sequences)\n",
    "        kalman = kalman.em(X=X_concat, n_iter=20)\n",
    "\n",
    "        song_preds = {}\n",
    "        song_targets = {}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y, durations, song_ids in val_loader:\n",
    "                X = ((X - mean) / std).to(device)\n",
    "                y_hat = model(X).cpu().numpy()\n",
    "                durations = durations.cpu().numpy()\n",
    "\n",
    "                for i, song_id in enumerate(song_ids):\n",
    "                    if song_id not in song_preds:\n",
    "                        song_preds[song_id] = {\"preds\": [], \"durs\": []}\n",
    "                        print(y[i].shape)\n",
    "                        song_targets[song_id] = y[i].cpu().numpy()\n",
    "\n",
    "                    song_preds[song_id][\"preds\"].append(y_hat[i])\n",
    "                    song_preds[song_id][\"durs\"].append(durations[i])\n",
    "\n",
    "        y_song_pred_smooth = []\n",
    "        y_song_pred_unsmooth = []\n",
    "        y_song_true = []\n",
    "\n",
    "        fold_song_results = []\n",
    "        beat_uncertainty = {}\n",
    "        for song_id in song_preds:\n",
    "            preds = np.vstack(song_preds[song_id][\"preds\"])\n",
    "            durs = np.hstack(song_preds[song_id][\"durs\"])\n",
    "\n",
    "            smoothed_states, smoothed_covs = kalman.smooth(preds)\n",
    "            song_pred_smooth = np.average(smoothed_states, axis=0, weights=durs)\n",
    "\n",
    "            weights = durs / durs.sum()\n",
    "            song_var = np.sum((weights ** 2)[:, None] * np.diagonal(smoothed_covs, axis1=1, axis2=2), axis=0)\n",
    "            song_std = np.sqrt(song_var)\n",
    "            song_ci = 1.96 * song_std\n",
    "\n",
    "            var_valence = smoothed_covs[:, 0, 0]\n",
    "            var_arousal = smoothed_covs[:, 1, 1]\n",
    "\n",
    "            std_valence = np.sqrt(var_valence)\n",
    "            std_arousal = np.sqrt(var_arousal)\n",
    "\n",
    "            ci_valence = 1.96 * std_valence\n",
    "            ci_arousal = 1.96 * std_arousal\n",
    "\n",
    "            beat_uncertainty[song_id] = {\n",
    "                \"mean\": smoothed_states,              \n",
    "                \"cov\": smoothed_covs,           \n",
    "                \"ci_valence\": ci_valence,       \n",
    "                \"ci_arousal\": ci_arousal,       \n",
    "                \"durations\": durs              \n",
    "            }\n",
    "\n",
    "            song_pred_unsmooth = np.average(\n",
    "                preds,\n",
    "                axis=0,\n",
    "                weights=durs\n",
    "            )\n",
    "\n",
    "            fold_song_results.append({\n",
    "                \"song_id\": song_id,\n",
    "                \"song_ci\": song_ci,\n",
    "                \"true_valence\": song_targets[song_id][0],\n",
    "                \"true_arousal\": song_targets[song_id][1],\n",
    "                \"pred_valence\": song_pred_unsmooth[0],\n",
    "                \"pred_arousal\": song_pred_unsmooth[1],\n",
    "                \"pred_valence_smooth\": song_pred_smooth[0],\n",
    "                \"pred_arousal_smooth\": song_pred_smooth[1],\n",
    "            })\n",
    "\n",
    "            y_song_pred_smooth.append(song_pred_smooth)\n",
    "            y_song_pred_unsmooth.append(song_pred_unsmooth)\n",
    "            y_song_true.append(song_targets[song_id])\n",
    "        \n",
    "        per_fold_beat_uncertainty[fold] = beat_uncertainty\n",
    "\n",
    "        y_song_pred_smooth = np.array(y_song_pred_smooth)\n",
    "        y_song_pred_unsmooth = np.array(y_song_pred_unsmooth)\n",
    "        y_song_true = np.array(y_song_true)\n",
    "\n",
    "        r_valence, _ = pearsonr(y_song_true[:, 0], y_song_pred_smooth[:, 0])\n",
    "        r_arousal, _ = pearsonr(y_song_true[:, 1], y_song_pred_smooth[:, 1])\n",
    "\n",
    "        r_valence_un, _ = pearsonr(y_song_true[:, 0], y_song_pred_unsmooth[:, 0])\n",
    "        r_arousal_un, _ = pearsonr(y_song_true[:, 1], y_song_pred_unsmooth[:, 1])\n",
    "\n",
    "        sm_val_r.append(r_valence)\n",
    "        sm_aro_r.append(r_arousal)\n",
    "\n",
    "        unsm_val_r.append(r_valence_un)\n",
    "        unsm_aro_r.append(r_arousal_un)\n",
    "\n",
    "        all_songs_val_and_aro.extend(fold_song_results)\n",
    "    \n",
    "    return (fold_results, \n",
    "            all_songs_val_and_aro, \n",
    "            unsm_val_r, \n",
    "            sm_val_r, \n",
    "            unsm_aro_r, \n",
    "            sm_aro_r,\n",
    "            model,\n",
    "            mean,\n",
    "            std,\n",
    "            input_dim,\n",
    "            kalman)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1001eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 of 10 =====\n",
      "Epoch 01 | Train MSE: 0.0512 | Val MSE: 0.0445\n",
      "Epoch 02 | Train MSE: 0.0453 | Val MSE: 0.0436\n",
      "Epoch 03 | Train MSE: 0.0436 | Val MSE: 0.0449\n",
      "Epoch 04 | Train MSE: 0.0429 | Val MSE: 0.0432\n",
      "Epoch 05 | Train MSE: 0.0421 | Val MSE: 0.0434\n",
      "Epoch 06 | Train MSE: 0.0416 | Val MSE: 0.0452\n",
      "Epoch 07 | Train MSE: 0.0416 | Val MSE: 0.0444\n",
      "Epoch 08 | Train MSE: 0.0405 | Val MSE: 0.0431\n",
      "Epoch 09 | Train MSE: 0.0399 | Val MSE: 0.0442\n",
      "Epoch 10 | Train MSE: 0.0400 | Val MSE: 0.0443\n",
      "Epoch 11 | Train MSE: 0.0392 | Val MSE: 0.0422\n",
      "Epoch 12 | Train MSE: 0.0392 | Val MSE: 0.0427\n",
      "Epoch 13 | Train MSE: 0.0390 | Val MSE: 0.0445\n",
      "Epoch 14 | Train MSE: 0.0388 | Val MSE: 0.0429\n",
      "Epoch 15 | Train MSE: 0.0382 | Val MSE: 0.0428\n",
      "Epoch 16 | Train MSE: 0.0382 | Val MSE: 0.0431\n",
      "Epoch 17 | Train MSE: 0.0377 | Val MSE: 0.0438\n",
      "Epoch 18 | Train MSE: 0.0372 | Val MSE: 0.0428\n",
      "Epoch 19 | Train MSE: 0.0370 | Val MSE: 0.0437\n",
      "Epoch 20 | Train MSE: 0.0368 | Val MSE: 0.0432\n",
      "Epoch 21 | Train MSE: 0.0364 | Val MSE: 0.0437\n",
      "Epoch 22 | Train MSE: 0.0366 | Val MSE: 0.0440\n",
      "Epoch 23 | Train MSE: 0.0359 | Val MSE: 0.0446\n",
      "Epoch 24 | Train MSE: 0.0357 | Val MSE: 0.0455\n",
      "Epoch 25 | Train MSE: 0.0354 | Val MSE: 0.0434\n",
      "Epoch 26 | Train MSE: 0.0351 | Val MSE: 0.0433\n",
      "Epoch 27 | Train MSE: 0.0352 | Val MSE: 0.0434\n",
      "Epoch 28 | Train MSE: 0.0351 | Val MSE: 0.0429\n",
      "Epoch 29 | Train MSE: 0.0349 | Val MSE: 0.0432\n",
      "Epoch 30 | Train MSE: 0.0347 | Val MSE: 0.0454\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "results = full_monty(device)\n",
    "\n",
    "fold_results = np.array(results[0])\n",
    "preds_and_true = results[1]\n",
    "df = pd.DataFrame(preds_and_true)\n",
    "df.to_csv(\"deam_song_predictions.csv\", index=False)\n",
    "unsm_valence = results[2]\n",
    "sm_valence = results[3]\n",
    "unsm_arousal = results[4]\n",
    "sm_arousal = results[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866c86f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7866c86f",
    "outputId": "635e07e8-c5cb-42ab-d75d-f02cfc5c8a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV Results:\n",
      "Mean MSE: 0.0423\n",
      "Std  MSE: 0.0026\n",
      "Smoothed valence r: 0.533 ± 0.063\n",
      "Smoothed arousal r: 0.741 ± 0.021\n",
      "Unsmoothed valence r: 0.534 ± 0.062\n",
      "Unsmoothed arousal r: 0.743 ± 0.020\n"
     ]
    }
   ],
   "source": [
    "print(\"10-Fold CV Results:\")\n",
    "print(f\"Mean MSE: {fold_results.mean():.4f}\")\n",
    "print(f\"Std  MSE: {fold_results.std():.4f}\")\n",
    "\n",
    "print(f\"Smoothed valence r: {np.mean(sm_valence):.3f} ± {np.std(sm_valence):.3f}\")\n",
    "print(f\"Smoothed arousal r: {np.mean(sm_arousal):.3f} ± {np.std(sm_arousal):.3f}\")\n",
    "\n",
    "print(f\"Unsmoothed valence r: {np.mean(unsm_valence):.3f} ± {np.std(unsm_valence):.3f}\")\n",
    "print(f\"Unsmoothed arousal r: {np.mean(unsm_arousal):.3f} ± {np.std(unsm_arousal):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"deam_beat_regressor_updated.pt\"\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": results[-5].state_dict(),\n",
    "    \"input_dim\": results[-2],\n",
    "    \"mean\": results[-4].cpu(),\n",
    "    \"std\": results[-3].cpu(),\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500edcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(results[-1], \"updated_emotion_ssm.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
