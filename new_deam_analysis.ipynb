{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "24838144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fbc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "audio_dir = sorted(glob.glob(\"DEAM_Dataset/DEAM_audio/MEMD_audio/*.mp3\", recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78981a1",
   "metadata": {},
   "source": [
    "For tonight:\n",
    "\n",
    "2. figure out why ideal metrics change every time you run DEAM\n",
    "3. plots of songs for the ones that you think are interesting\n",
    "4. finalize your analysis points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fc5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_level_predictions():\n",
    "\n",
    "    anno_1_2000 = pd.read_csv(\"DEAM_Dataset/DEAM_Annotations/annotations/annotations averaged per song/song_level/static_annotations_averaged_songs_1_2000.csv\")\n",
    "    anno_2001_2058 = pd.read_csv(\"DEAM_Dataset/DEAM_Annotations/annotations/annotations averaged per song/song_level/static_annotations_averaged_songs_2000_2058.csv\")\n",
    "\n",
    "    annotations = pd.concat([anno_1_2000, anno_2001_2058])\n",
    "    \n",
    "    annotations = annotations.rename(columns={column: column.replace(\" \", \"\") for column in annotations.columns})\n",
    "\n",
    "    annotations['song_id'] = annotations['song_id'].astype(str)\n",
    "    annotations = annotations.drop(columns=[column for column in annotations.columns if column not in [\"song_id\", \"valence_mean\", \"arousal_mean\"]])\n",
    "    annotations['valence_mean'] = ((annotations['valence_mean'] - 1) / (9 - 1)) * (1 - (-1)) + (-1)\n",
    "    annotations['arousal_mean'] = ((annotations['arousal_mean'] - 1) / (9 - 1)) * (1 - (-1)) + (-1)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "354ec492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_from_audio(file):\n",
    "\n",
    "    y, sr = librosa.load(file)\n",
    "\n",
    "    mfcc_matrix = librosa.feature.mfcc(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_mfcc=20\n",
    "    )\n",
    "\n",
    "    mfcc_matrix = torch.tensor(mfcc_matrix, dtype=torch.float32)\n",
    "    mean = mfcc_matrix.mean(dim=1)\n",
    "    std = mfcc_matrix.std(dim=1)\n",
    "    min_ = mfcc_matrix.min(dim=1).values\n",
    "    max_ = mfcc_matrix.max(dim=1).values\n",
    "    X = torch.cat([mean, std, min_, max_], dim = 0)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fad8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cens_from_audio(file):\n",
    "    y, sr = librosa.load(file)\n",
    "\n",
    "    chroma_matrix = librosa.feature.chroma_cens(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_chroma=12\n",
    "    )\n",
    "\n",
    "    chroma_matrix = torch.tensor(chroma_matrix, dtype=torch.float32)\n",
    "    mean = chroma_matrix.mean(dim=1)\n",
    "    std = chroma_matrix.std(dim=1)\n",
    "    min_ = chroma_matrix.min(dim=1).values\n",
    "    max_ = chroma_matrix.max(dim=1).values\n",
    "    X = torch.cat([mean, std, min_, max_], dim = 0)\n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mfcc_tensor():\n",
    "\n",
    "    audio_dir = sorted(glob.glob(\"DEAM_Dataset/DEAM_audio/MEMD_audio/*.mp3\", recursive=True))\n",
    "    X = []\n",
    "\n",
    "    for song in tqdm(audio_dir, total=len(audio_dir)):\n",
    "        mfcc_tensor = get_mfcc_from_audio(song)\n",
    "        reshaped = mfcc_tensor.view(1, -1)\n",
    "        X.append(reshaped)\n",
    "    \n",
    "    X = torch.stack(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c91cdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dual_feature_tensor():\n",
    "\n",
    "    audio_dir = sorted(glob.glob(\"DEAM_Dataset/DEAM_audio/MEMD_audio/*.mp3\", recursive=True))\n",
    "    \n",
    "    X = []\n",
    "\n",
    "    for song in tqdm(audio_dir, total=len(audio_dir)):\n",
    "        mfcc_tensor = get_mfcc_from_audio(song)\n",
    "        cens_tensor = get_cens_from_audio(song)\n",
    "        reshaped = torch.cat([mfcc_tensor, cens_tensor], dim=0)\n",
    "        X.append(reshaped)\n",
    "    \n",
    "    X = torch.stack(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "91af253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_tensor(annotations_df):\n",
    "    valence = annotations_df['valence_mean'].to_numpy().astype(np.float32)\n",
    "    valence = torch.from_numpy(valence).view(-1,1)\n",
    "\n",
    "    arousal = annotations_df['arousal_mean'].to_numpy().astype(np.float32)\n",
    "    arousal = torch.from_numpy(arousal).view(-1,1)\n",
    "\n",
    "    return torch.concat((valence, arousal), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c7895bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_creation(annotations_df, songs):\n",
    "\n",
    "    for (_, row), song in zip(annotations_df.iterrows(), songs):\n",
    "        assert row[\"song_id\"] == song[song.rindex(\"/\") + 1: song.index(\".\")]\n",
    "        assert row[\"valence_mean\"] > -1 and row[\"valence_mean\"] < 1\n",
    "        assert row[\"arousal_mean\"] > -1 and row[\"arousal_mean\"] < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55419ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_cc(y_pred, y_true):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "\n",
    "    covariance = np.mean((y_true - mean_true) * (y_pred - mean_pred))\n",
    "\n",
    "    ccc = (2 * covariance) / (\n",
    "        var_true + var_pred + (mean_true - mean_pred) ** 2\n",
    "    )\n",
    "\n",
    "    return ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "594406ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pass(X, y, lr, epochs, n_splits):\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_results = []\n",
    "\n",
    "    lowest_ccc = float(\"inf\")\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        mean = X_train.mean(dim=0)\n",
    "        std = X_train.std(dim=0) + 1e-8\n",
    "\n",
    "        X_train = (X_train - mean) / std\n",
    "        X_test = (X_test - mean) / std\n",
    "\n",
    "        model = EmotionRegressor(input_dim=X.shape[1])\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_train)\n",
    "            loss = criterion(preds, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_test)\n",
    "\n",
    "        valence_pred = preds[:, 0]\n",
    "        arousal_pred = preds[:, 1]\n",
    "\n",
    "        v_correlation_coefficient, _ = pearsonr(valence_pred.detach().cpu().numpy(), y_test[:, 0].detach().cpu().numpy())\n",
    "        a_correlation_coefficient, _ = pearsonr(arousal_pred.detach().cpu().numpy(), y_test[:, 1].detach().cpu().numpy())\n",
    "\n",
    "        v_ccc = concordance_cc(valence_pred.detach().cpu().numpy(), y_test[:, 0].detach().cpu().numpy())\n",
    "        a_ccc = concordance_cc(arousal_pred.detach().cpu().numpy(), y_test[:, 1].detach().cpu().numpy())\n",
    "\n",
    "        val_mse = mean_squared_error(valence_pred.detach().cpu().numpy(), y_test[:, 0].detach().cpu().numpy())\n",
    "        aro_mse = mean_squared_error(arousal_pred.detach().cpu().numpy(), y_test[:, 1].detach().cpu().numpy())\n",
    "\n",
    "        if v_ccc < lowest_ccc:\n",
    "            checkpoint = {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"input_dim\": X.shape[1],\n",
    "                \"X_mean\": mean,\n",
    "                \"X_std\": std\n",
    "            }\n",
    "            torch.save(checkpoint, \"emotion_regressor.pt\")\n",
    "\n",
    "        fold_results.append({fold : {\n",
    "            \"valence_pred\": valence_pred,\n",
    "            \"arousal_pred\": arousal_pred,\n",
    "            \"valence_true\": y_test[:, 0].cpu().numpy(),\n",
    "            \"arousal_true\": y_test[:, 1].cpu().numpy(),\n",
    "            \"valence_ccc\": v_ccc,\n",
    "            \"arousal_ccc\": a_ccc,\n",
    "            \"valence_r\": v_correlation_coefficient,\n",
    "            \"arousal_r\": a_correlation_coefficient,\n",
    "            \"val_mse\": val_mse,\n",
    "            \"aro_mse\": aro_mse\n",
    "        }\n",
    "        })\n",
    "    \n",
    "    return fold_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2532b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ideal_training_metrics(X, y):\n",
    "\n",
    "    lrs = [1e-3, 1e-4, 1e-5, 3e-3, 2e-3]\n",
    "    epochs = [20, 30, 40, 50]\n",
    "    splits = [5, 10, 15, 20]\n",
    "\n",
    "    best_ccc = float('-inf')\n",
    "\n",
    "    for epoch in epochs:\n",
    "        for lr in lrs:\n",
    "            for split in splits:\n",
    "                results = training_pass(X, y, lr, epoch, split)\n",
    "                cccs = []\n",
    "                for i in range(0, split):\n",
    "                    result = results[i]\n",
    "                    cccs.append(result[i + 1][\"valence_ccc\"])\n",
    "                ccc = np.mean(np.asarray(cccs)) \n",
    "                if ccc > best_ccc:\n",
    "                    best_results = {\"lr\": lr, \"split\": split, \"epoch\": epoch}\n",
    "                    best_ccc = ccc\n",
    "    \n",
    "    return best_results, best_ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_med_idx(results, split):\n",
    "\n",
    "    cccs = []\n",
    "\n",
    "    for i in range(0, split):\n",
    "        result = results[i]\n",
    "        cccs.append(result[i + 1][\"valence_ccc\"])\n",
    "    median_idx = np.argsort(np.asarray(cccs))[len(cccs)//2]\n",
    "    return median_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bbdb4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(idx, v_predictions, v_truths, a_predictions, a_truths):\n",
    "\n",
    "    vp, ap = float(v_predictions[idx]), float(a_predictions[idx])\n",
    "    vt, at = float(v_truths[idx]), float(a_truths[idx])\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter([vp], [ap], c='C0', label='Prediction', s=120)\n",
    "    plt.scatter([vt], [at], c='C1', label='Ground truth', s=120)\n",
    "    plt.arrow(vp, ap, vt - vp, at - ap,\n",
    "              head_width=0.02, head_length=0.02,\n",
    "              length_includes_head=True, color='gray', alpha=0.7)\n",
    "    plt.xlabel('Valence')\n",
    "    plt.ylabel('Arousal')\n",
    "    plt.title(f'Prediction vs Truth (sample {idx})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(-1.1, 1.1)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ead85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_valid_data(data):\n",
    "    return (data.all() <= 1 and data.all() >= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_monty():\n",
    "    \n",
    "    annotations = get_song_level_predictions()\n",
    "    annotations = annotations.sort_values(by='song_id')\n",
    "    \n",
    "    X = create_dual_feature_tensor()\n",
    "    \n",
    "    y = create_label_tensor(annotations)\n",
    "\n",
    "    check_dataset_creation(annotations, audio_dir)\n",
    "\n",
    "    best_results = find_ideal_training_metrics(X, y)\n",
    "    \n",
    "    print(\"-----Best Result-----\")\n",
    "    print(f\"LR: {best_results[0][\"lr\"]} | Num Epochs: {best_results[0][\"split\"]} | Num Splits: {best_results[0][\"epoch\"]}\")\n",
    "    \n",
    "    results = training_pass(X, y, best_results[0][\"lr\"], best_results[0][\"epoch\"], best_results[0][\"split\"])\n",
    "\n",
    "    median_idx = find_med_idx(results, best_results[0][\"split\"])\n",
    "    print(f\"Median Index: {median_idx}\")\n",
    "\n",
    "    v_predictions = results[median_idx][median_idx + 1][\"valence_pred\"].detach().cpu().numpy()\n",
    "    v_truths = results[median_idx][median_idx + 1][\"valence_true\"]\n",
    "\n",
    "    a_predictions = results[median_idx][median_idx + 1][\"arousal_pred\"].detach().cpu().numpy()\n",
    "    a_truths = results[median_idx][median_idx + 1][\"arousal_true\"]\n",
    "\n",
    "    check1 = assert_valid_data(v_predictions)\n",
    "    check2 = assert_valid_data(v_truths)\n",
    "    check3 = assert_valid_data(a_predictions)\n",
    "    check4 = assert_valid_data(a_truths)\n",
    "\n",
    "    if not (check1 and check2 and check3 and check4):\n",
    "        raise ValueError(\"Invalid data\")\n",
    "\n",
    "    idxs = set()\n",
    "    for i in range(5):\n",
    "        idxs.add(random.randint(0, len(v_predictions)))\n",
    "\n",
    "    for idx in idxs:\n",
    "        plot_predictions(idx, v_predictions, v_truths, a_predictions, a_truths)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f97dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_monty()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
