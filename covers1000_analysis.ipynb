{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8eb7705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "from scipy.io import loadmat\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import re\n",
    "import math\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "af5457f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "4db389e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_first_release_data():\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk('Metadata'):\n",
    "        for dir in dirnames:\n",
    "            total_lines = []\n",
    "            for file in os.walk(os.path.join(dirpath, dir)):\n",
    "                for file_name in file[2]:\n",
    "                    with open(os.path.join(dirpath, dir, file_name)) as f:\n",
    "                        lines = [line.rstrip(\"\\n\") for line in f]\n",
    "                        year = lines[2]\n",
    "                        if \",\" in year:\n",
    "                            year = year[year.index(\",\"):]\n",
    "                        year = re.sub(r'[^0-9]', '', year)\n",
    "                        lines[2] = year\n",
    "                        total_lines.append(lines)\n",
    "                found_first_release = False\n",
    "                for line in total_lines:\n",
    "                    if len(line) == 4 and \"first\" in line[3].lower():\n",
    "                        found_first_release = True\n",
    "                if not found_first_release:\n",
    "                    years = []\n",
    "                    for line in total_lines:\n",
    "                        years.append(int(line[2]))\n",
    "                    first_year = min(years)\n",
    "                    years = [str(year) for year in years]\n",
    "                    total_lines[years.index(str(first_year))].append(\"First release\")\n",
    "                    for line, file_name in zip(total_lines, file[2]):\n",
    "                        with open(os.path.join(dirpath, dir, file_name), 'w') as f:\n",
    "                                for l in line:\n",
    "                                    f.write(f\"{l}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c6d44a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_info():\n",
    "\n",
    "    song_dict = defaultdict(dict)\n",
    "\n",
    "    songs = glob.glob(\"Metadata/**/*.txt\", recursive=True)\n",
    "    \n",
    "    for file in tqdm(songs):\n",
    "        with open(file) as f:\n",
    "                key1 = file[file.index(\"/\") + 1: file.rindex(\"/\")]\n",
    "                key2 = file[file.rindex(\"/\") + 1:file.index(\".\")]\n",
    "                lines = [line.rstrip(\"\\n\") for line in f]\n",
    "                song_dict[key1][key2] = {\"Metadata\": lines}\n",
    "                              \n",
    "    \n",
    "    return song_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "46feec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_info(song_dict):\n",
    "\n",
    "    mfcc_files = glob.glob(\"MFCCs/**/*.mat\", recursive=True)\n",
    "    cens_files = glob.glob(\"CENS/**/*.mat\", recursive=True)\n",
    "\n",
    "    num = len(mfcc_files)\n",
    "\n",
    "    for mfcc_file, cens_file in zip(mfcc_files, cens_files):\n",
    "        mat1 = loadmat(mfcc_file)\n",
    "        mfcc_matrix = mat1['XMFCC'].squeeze()\n",
    "        mfcc_matrix = torch.tensor(mfcc_matrix, dtype=torch.float32)\n",
    "        mean = mfcc_matrix.mean(dim=1)\n",
    "        std = mfcc_matrix.std(dim=1)\n",
    "        min_ = mfcc_matrix.min(dim=1).values\n",
    "        max_ = mfcc_matrix.max(dim=1).values\n",
    "        mfcc_tensor = torch.cat([mean, std, min_, max_], dim = 0)\n",
    "\n",
    "        mat2 = loadmat(cens_file)\n",
    "        cens_matrix = mat2[\"XCENS\"].squeeze()\n",
    "        cens_matrix = torch.tensor(cens_matrix, dtype=torch.float32)\n",
    "        mean = cens_matrix.mean(dim=1)\n",
    "        std = cens_matrix.std(dim=1)\n",
    "        min_ = cens_matrix.min(dim=1).values\n",
    "        max_ = cens_matrix.max(dim=1).values\n",
    "        cens_tensor = torch.cat([mean, std, min_, max_], dim = 0)\n",
    "\n",
    "        key1 = mfcc_file[mfcc_file.index(\"/\") + 1: mfcc_file.rindex(\"/\")]\n",
    "        key2 = mfcc_file[mfcc_file.rindex(\"/\") + 1: mfcc_file.index(\"_\")]\n",
    "        song_dict[key1][key2][\"X\"] = torch.cat([mfcc_tensor, cens_tensor], dim=0)\n",
    "\n",
    "    return song_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7d7d0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_tensor(song_dict):\n",
    "\n",
    "    X = []\n",
    "    song_list = []\n",
    "\n",
    "    for folder in sorted(song_dict):\n",
    "        for song in sorted(song_dict[folder]):\n",
    "            song_list.append(song)\n",
    "            X.append(song_dict[folder][song][\"X\"])\n",
    "    X = torch.stack(X)\n",
    "    return X, song_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "4e22b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_songs_by_feature(song_dict):\n",
    "\n",
    "    # songs grouped based on when the original was released\n",
    "    first_release_groupings = {}\n",
    "\n",
    "    # songs grouped based on when the cover was released\n",
    "    cover_release_groupings = {}\n",
    "\n",
    "    # songs grouped by number of covers released\n",
    "    songs_with_more_than_3_covers = {}\n",
    "\n",
    "    # first release songs mapped to their corresponding covers\n",
    "    first_releases_to_covers = {}\n",
    "\n",
    "    for folder in song_dict:\n",
    "        if len(song_dict[folder]) >=4:\n",
    "            songs_with_more_than_3_covers[folder] = [song for song in song_dict[folder]]\n",
    "        for song in song_dict[folder]:\n",
    "            if (\"First release\" in song_dict[folder][song][\"Metadata\"] \n",
    "                or \"First recording\" in song_dict[folder][song][\"Metadata\"] \n",
    "                or \"First performance\" in song_dict[folder][song][\"Metadata\"]):\n",
    "                first_releases_to_covers[song] = [tune for tune in song_dict[folder] if tune != song]\n",
    "                year = song_dict[folder][song][\"Metadata\"][2]\n",
    "                if \",\" in year:\n",
    "                    year = year[year.index(\",\"):]\n",
    "                year = re.sub(r'[^0-9]', '', year)\n",
    "                if f\"{year[:3]}0\" in first_release_groupings:\n",
    "                    first_release_groupings[f\"{year[:3]}0\"].append(song)\n",
    "                else:\n",
    "                    first_release_groupings[f\"{year[:3]}0\"] = [song]\n",
    "            else:\n",
    "                year = song_dict[folder][song][\"Metadata\"][2]\n",
    "                if \",\" in year:\n",
    "                    year = year[year.index(\",\"):]\n",
    "                year = re.sub(r'[^0-9]', '', year)\n",
    "                if f\"{year[:3]}0\" in cover_release_groupings:\n",
    "                    cover_release_groupings[f\"{year[:3]}0\"].append(song)\n",
    "                else:\n",
    "                    cover_release_groupings[f\"{year[:3]}0\"] = [song]\n",
    "\n",
    "    return (\n",
    "        first_release_groupings,\n",
    "        cover_release_groupings,\n",
    "        songs_with_more_than_3_covers,\n",
    "        first_releases_to_covers\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c22cafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "55d16869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X):\n",
    "\n",
    "    ckpt = torch.load(\"emotion_regressor.pt\")\n",
    "\n",
    "    model = EmotionRegressor(ckpt[\"input_dim\"]).to(device)\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    X = (X - ckpt[\"X_mean\"]) / ckpt[\"X_std\"]\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5faa8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cover_distances(originals, song_tensors, original_val, original_aro):\n",
    "    \n",
    "    cover_distances = []\n",
    "    for cover in originals:\n",
    "        cover_val = song_tensors[cover][0]\n",
    "        cover_aro = song_tensors[cover][1]\n",
    "\n",
    "        distance = math.hypot(cover_val - original_val, cover_aro - original_aro)\n",
    "        cover_distances.append(distance)\n",
    "    \n",
    "    distance = sum(cover_distances)/len(cover_distances)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "f656589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(song_list,\n",
    "                      preds,\n",
    "                      originals_to_covers, \n",
    "                      first_release_groupings, \n",
    "                      cover_release_groupings, \n",
    "                      song_with_more_than_3):\n",
    "\n",
    "    global_distance_metrics = {}\n",
    "    \n",
    "    song_tensors = {}\n",
    "    for i, row in enumerate(preds):\n",
    "        song_tensors[song_list[i]] = row\n",
    "\n",
    "    org_to_cover_distances = []\n",
    "    for original in originals_to_covers:\n",
    "        original_val = song_tensors[original][0]\n",
    "        original_aro = song_tensors[original][1]\n",
    "\n",
    "        cover_distance = find_cover_distances(originals_to_covers[original], song_tensors, original_val, original_aro)\n",
    "        org_to_cover_distances.append(cover_distance)\n",
    "\n",
    "    avg_distance = sum(org_to_cover_distances)/len(org_to_cover_distances)\n",
    "    global_distance_metrics[\"overall average distance\"] = avg_distance\n",
    "\n",
    "    distances_by_year = {}\n",
    "    for year in first_release_groupings:\n",
    "        distances = []\n",
    "        for original in first_release_groupings[year]:\n",
    "            original_val = song_tensors[original][0]\n",
    "            original_aro = song_tensors[original][1]\n",
    "\n",
    "            year_distance = find_cover_distances(originals_to_covers[original], song_tensors, original_val, original_aro)\n",
    "            distances.append(year_distance)\n",
    "\n",
    "        distances_by_year[year] = float(f\"{sum(distances)/len(distances):.4f}\")\n",
    "\n",
    "    global_distance_metrics[\"dist by first release year\"] = distances_by_year\n",
    "\n",
    "    covers_distances_by_year = {}\n",
    "    for year in cover_release_groupings:\n",
    "        distances = []\n",
    "        for song in cover_release_groupings[year]:\n",
    "            cover_val = song_tensors[song][0]\n",
    "            cover_aro = song_tensors[song][1]\n",
    "\n",
    "            original = [org for org in originals_to_covers if song in originals_to_covers[org]]\n",
    "            original_val = song_tensors[original[0]][0]\n",
    "            original_aro = song_tensors[original[0]][1]\n",
    "\n",
    "            distance = math.hypot(cover_val - original_val, cover_aro - original_aro)\n",
    "            distances.append(distance)\n",
    "\n",
    "        covers_distances_by_year[year] = float(f\"{sum(distances)/len(distances):.4f}\")\n",
    "    \n",
    "    global_distance_metrics[\"dist by cover year\"] = covers_distances_by_year\n",
    "\n",
    "    distances = []\n",
    "    for folder in song_with_more_than_3:\n",
    "        cover_preds = []\n",
    "        cover_distances = []\n",
    "        for song in song_with_more_than_3[folder]:\n",
    "            if song in originals_to_covers:\n",
    "                original_val = song_tensors[song][0]\n",
    "                original_aro = song_tensors[song][1]\n",
    "            else:\n",
    "                cover_val = song_tensors[song][0]\n",
    "                cover_aro = song_tensors[song][1]\n",
    "                cover_preds.append((cover_val, cover_aro))\n",
    "        for cover in cover_preds:\n",
    "            distance = math.hypot(cover[0] - original_val, cover[1] - original_aro)\n",
    "            cover_distances.append(distance)  \n",
    "        distance = sum(cover_distances)/len(cover_distances)\n",
    "        distances.append(distance)\n",
    "\n",
    "    avg_distance = sum(distances)/len(distances)\n",
    "    global_distance_metrics[\"3+ covers avg\"] = avg_distance\n",
    "\n",
    "    return global_distance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "d814037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_monty():\n",
    "    \n",
    "    add_first_release_data()\n",
    "    song_dict = get_song_info()\n",
    "    song_dict = get_audio_info(song_dict)\n",
    "    X, song_list = create_feature_tensor(song_dict)\n",
    "\n",
    "    grouped_dictionaries = group_songs_by_feature(song_dict)\n",
    "    first_release_groupings = grouped_dictionaries[0]\n",
    "    cover_release_groupings = grouped_dictionaries[1]\n",
    "    song_with_more_than_3 = grouped_dictionaries[2]\n",
    "    originals_to_covers = grouped_dictionaries[3]\n",
    "    \n",
    "    preds = evaluate_model(X)\n",
    "\n",
    "    distance_dict = compute_distances(song_list,\n",
    "                                      preds,\n",
    "                                      originals_to_covers, \n",
    "                                      first_release_groupings, \n",
    "                                      cover_release_groupings, \n",
    "                                      song_with_more_than_3)\n",
    "\n",
    "    return distance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "5b7c67c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 46040.15it/s]\n"
     ]
    }
   ],
   "source": [
    "distance_dict = full_monty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ad888cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall average distance': 0.21010733888295982, 'dist by first release year': {'1980': 0.2361, '1950': 0.2108, '2000': 0.1999, '1970': 0.188, '1990': 0.2349, '2010': 0.1661, '1930': 0.2266, '1960': 0.2064, '1940': 0.1706, '1920': 0.2177, '1900': 0.4132}, 'dist by cover year': {'2010': 0.2119, '1970': 0.1907, '1960': 0.2206, '1990': 0.1996, '2000': 0.2324, '1950': 0.2435, '1930': 0.1623, '1980': 0.2076, '1940': 0.26, '1900': 0.4039}, '3+ covers avg': 0.23195747739719527}\n"
     ]
    }
   ],
   "source": [
    "print(distance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5361c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "\n",
    "# 391 - no words\n",
    "# 368 - cross genre (Bon Jovi to screamo catamenia)\n",
    "# 327: Grateful Dead to Courtney Barnett\n",
    "# 307: Interesting piano to brass jazz example\n",
    "# 313: Funny cover of Only Happy when It Rains by Richard Cheese\n",
    "# 259: Different song, difficult example with very stylistically different vocals\n",
    "# 261: Vocal to jazz example (neat!)\n",
    "# 232: Very strange cover of Fleetwood Mac\n",
    "# 207: Cross gender\n",
    "# 156: Jerry Garcia studio (Deal) versus Grateful Dead live\n",
    "# 182: Cross genre (R&B to reggae)\n",
    "# 184: Very different instruments\n",
    "# 127: Difficult example (old vocals not very distinct, needs to rely on pitch)\n",
    "# 133: Difficult examples (stylistically very different)\n",
    "# 76: Good Cross Genre\n",
    "# 8: A good example of where the notes are quite different\n",
    "# 12: Good example of screamo cross genre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
